{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jonasaacampos/uso-de-express-es-regulares-no-tratamento-de-dados?scriptVersionId=121363440\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Uso de expressões regulares para Limpeza de dados: Funções anônimas e Pandas\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-07T14:43:31.463937Z","iopub.execute_input":"2023-03-07T14:43:31.464912Z","iopub.status.idle":"2023-03-07T14:43:31.493434Z","shell.execute_reply.started":"2023-03-07T14:43:31.46487Z","shell.execute_reply":"2023-03-07T14:43:31.4925Z"}}},{"cell_type":"code","source":"!pip install faker","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:31.080543Z","iopub.execute_input":"2023-03-07T17:16:31.081304Z","iopub.status.idle":"2023-03-07T17:16:47.28438Z","shell.execute_reply.started":"2023-03-07T17:16:31.081258Z","shell.execute_reply":"2023-03-07T17:16:47.282402Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting faker\n  Downloading Faker-17.6.0-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.1 in /opt/conda/lib/python3.7/site-packages (from faker) (4.4.0)\nRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.7/site-packages (from faker) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\nInstalling collected packages: faker\nSuccessfully installed faker-17.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# biblioteca para geração de dados aleatórios\nfrom faker import Faker\n\n# biblioteca para usarmos Regular Expression 'regex' com o pyuthon\nimport re\n\n# biblioteca de análise e manipulação de dados\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:47.287038Z","iopub.execute_input":"2023-03-07T17:16:47.287717Z","iopub.status.idle":"2023-03-07T17:16:47.382085Z","shell.execute_reply.started":"2023-03-07T17:16:47.287658Z","shell.execute_reply":"2023-03-07T17:16:47.380811Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# criando nosso gerador e determinando o número de nossa amostra. Neste exemplo faremos a geração de 10 mil endereços fictícios\nfaker = Faker()\nn = 10_000\n","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:47.383652Z","iopub.execute_input":"2023-03-07T17:16:47.384013Z","iopub.status.idle":"2023-03-07T17:16:47.433368Z","shell.execute_reply.started":"2023-03-07T17:16:47.383981Z","shell.execute_reply":"2023-03-07T17:16:47.43198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# função de preenche um conjunto de dados com dados aleatórios\n\ndef preenche_dataset():\n    return pd.Series([faker.address() for i in range (n)])","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:47.436515Z","iopub.execute_input":"2023-03-07T17:16:47.436931Z","iopub.status.idle":"2023-03-07T17:16:47.443423Z","shell.execute_reply.started":"2023-03-07T17:16:47.436891Z","shell.execute_reply":"2023-03-07T17:16:47.441958Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# gerando um conjunto de dados\ndf_enderecos = preenche_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:47.445464Z","iopub.execute_input":"2023-03-07T17:16:47.445975Z","iopub.status.idle":"2023-03-07T17:16:49.68839Z","shell.execute_reply.started":"2023-03-07T17:16:47.445938Z","shell.execute_reply":"2023-03-07T17:16:49.686694Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#amostra dos dados\ndf_enderecos","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:49.690291Z","iopub.execute_input":"2023-03-07T17:16:49.690687Z","iopub.status.idle":"2023-03-07T17:16:49.704719Z","shell.execute_reply.started":"2023-03-07T17:16:49.690651Z","shell.execute_reply":"2023-03-07T17:16:49.70357Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0         3395 Lisa Knolls Suite 307\\nJuanmouth, GA 72551\n1                                USNS Jones\\nFPO AP 61253\n2             877 Joseph Square\\nElliottchester, PR 37449\n3                        Unit 4466 Box 8352\\nDPO AE 03524\n4             5338 Jackson Shores\\nEast Colleen, DE 05698\n                              ...                        \n9995              1193 Quinn Loop\\nGrantborough, HI 94415\n9996    9445 Brent Crossroad Apt. 947\\nLake Jamesfort,...\n9997                 01403 Jane Flat\\nMarymouth, NY 81959\n9998    076 Angelica Parkways Suite 861\\nWeststad, PW ...\n9999    6807 Kenneth Passage Apt. 017\\nStricklandfort,...\nLength: 10000, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"Nested dados, queremos extrair os dados: \n\n- **Estado:** sigla de duas letras após a vírgula, e separadas por um espaço do código postal\n- **Código Postal:** código numérico no final de cada linha\n\nSeguindo este padrão, (_PW 69878_), vamos considerar o trecho de cada linha que conhenha\n\n- [ ] 2 letras\n- [ ] 1 espaço\n- [ ] 5 números\n\nEm Regex, este padrão é escrito como `\\w{2} \\d{5}`","metadata":{}},{"cell_type":"code","source":"# definindo o padrão da expressão regular\n\npattern = \"\\w{2} \\d{5}\"","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:49.707058Z","iopub.execute_input":"2023-03-07T17:16:49.70769Z","iopub.status.idle":"2023-03-07T17:16:49.77097Z","shell.execute_reply.started":"2023-03-07T17:16:49.707646Z","shell.execute_reply":"2023-03-07T17:16:49.769662Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Caso 1: Funções anônima e expressão regular (lambda functions and regex)\n\nO map() é uma função que executa determinada ação em cada item de um objeto. No nosso caso, para cada linha de endereço, vamos:\n\n1. procurar pelo nosso padrão (2 letras + espaço + 5 números)\n1. separar este trecho encontrado por meio do espaçamento entre as letras e números\n1. renomear as colunas para e inserir cada dado em sua respectiva coluna\n","metadata":{}},{"cell_type":"code","source":"(\n    (df_enderecos)\n        .map (lambda x: (re.search(pattern, x).group()))\n        .str .split(\" \", expand=True)\n        .rename(columns={0: \"state\", 1:\"zip_code\"})    \n)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:16:49.773045Z","iopub.execute_input":"2023-03-07T17:16:49.773866Z","iopub.status.idle":"2023-03-07T17:16:49.866556Z","shell.execute_reply.started":"2023-03-07T17:16:49.773806Z","shell.execute_reply":"2023-03-07T17:16:49.864526Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     state zip_code\n0       GA    72551\n1       AP    61253\n2       PR    37449\n3       AE    03524\n4       DE    05698\n...    ...      ...\n9995    HI    94415\n9996    NJ    95105\n9997    NY    81959\n9998    PW    45133\n9999    FL    08872\n\n[10000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GA</td>\n      <td>72551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AP</td>\n      <td>61253</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PR</td>\n      <td>37449</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AE</td>\n      <td>03524</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DE</td>\n      <td>05698</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>HI</td>\n      <td>94415</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>NJ</td>\n      <td>95105</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>NY</td>\n      <td>81959</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>PW</td>\n      <td>45133</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>FL</td>\n      <td>08872</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Caso 2: Pandas e regex de forma nativa\n\n","metadata":{}},{"cell_type":"code","source":"# separando os padrões de cada texto a ser encontrado\n\npattern_state = '\\w{2}'\npattern_zip_code = '\\d{5}'","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:21:07.803674Z","iopub.execute_input":"2023-03-07T17:21:07.804127Z","iopub.status.idle":"2023-03-07T17:21:07.810146Z","shell.execute_reply.started":"2023-03-07T17:21:07.804087Z","shell.execute_reply":"2023-03-07T17:21:07.808917Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Separamos nosso padrão de análise textual, e agora vamos fazer a extração de grupos nomeados em cada parão, utilizando o método `extract()` nativo do pandas.","metadata":{}},{"cell_type":"code","source":"df_enderecos.str.extract( r\"(?P<state>\\w{2}) (?P<zip_code>\\d{5})\" ) ","metadata":{"execution":{"iopub.status.busy":"2023-03-07T17:24:47.099555Z","iopub.execute_input":"2023-03-07T17:24:47.099995Z","iopub.status.idle":"2023-03-07T17:24:47.150314Z","shell.execute_reply.started":"2023-03-07T17:24:47.099958Z","shell.execute_reply":"2023-03-07T17:24:47.148782Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"     state zip_code\n0       GA    72551\n1       AP    61253\n2       PR    37449\n3       AE    03524\n4       DE    05698\n...    ...      ...\n9995    HI    94415\n9996    NJ    95105\n9997    NY    81959\n9998    PW    45133\n9999    FL    08872\n\n[10000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GA</td>\n      <td>72551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AP</td>\n      <td>61253</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PR</td>\n      <td>37449</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AE</td>\n      <td>03524</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DE</td>\n      <td>05698</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>HI</td>\n      <td>94415</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>NJ</td>\n      <td>95105</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>NY</td>\n      <td>81959</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>PW</td>\n      <td>45133</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>FL</td>\n      <td>08872</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Comparação entre as possibilidades\n\n```python\n# lambda function\n(\n    (df_enderecos)\n        .map (lambda x: (re.search(pattern, x).group()))\n        .str .split(\" \", expand=True)\n        .rename(columns={0: \"state\", 1:\"zip_code\"})    \n)\n\n# Pandas\ndf_enderecos.str.extract( r\"(?P<state>\\w{2}) (?P<zip_code>\\d{5})\" ) \n\n```\n\nAmbos os métodos trazem o mesmo resultado, todavia estilo do pandas é mais _pythônico_ e mais simples. **Todavia** este método é um pouco mais lento, mas nada que inviabilize o seu uso.\n\nNo próximo artigo farei uma análise do tempo de execução de ambos os cenários.","metadata":{}}]}